{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c545189c-4b51-4338-978a-e33299c49a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hint: Pulling without specifying how to reconcile divergent branches is\n",
      "hint: discouraged. You can squelch this message by running one of the following\n",
      "hint: commands sometime before your next pull:\n",
      "hint: \n",
      "hint:   git config pull.rebase false  # merge (the default strategy)\n",
      "hint:   git config pull.rebase true   # rebase\n",
      "hint:   git config pull.ff only       # fast-forward only\n",
      "hint: \n",
      "hint: You can replace \"git config\" with \"git config --global\" to set a default\n",
      "hint: preference for all repositories. You can also pass --rebase, --no-rebase,\n",
      "hint: or --ff-only on the command line to override the configured default per\n",
      "hint: invocation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from itertools import product\n",
    "## IMPORTANT: Make sure that \"Uniandes_Framework\" is in .gitignore\n",
    "framework_path = \"Uniandes_Framework\"\n",
    "\n",
    "if os.path.exists(framework_path):\n",
    "    # Pull updates if the framework is already cloned\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"-C\", framework_path, \"pull\"])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise Exception(f\"Error occurred while pulling updates from the framework: {e}\")\n",
    "else:\n",
    "    # Clone the framework if it is not already cloned\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"clone\", \"git@github.com:Phenomenology-group-uniandes/Uniandes_Framework.git\"])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise Exception(f\"Error occurred while cloning the framework: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd93c6b-8c94-4943-8632-23c9fe20a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from Uniandes_Framework.delphes_reader import DelphesLoader \n",
    "from Uniandes_Framework.delphes_reader import classifier \n",
    "from Uniandes_Framework.delphes_reader import root_analysis \n",
    "from Uniandes_Framework.delphes_reader import Quiet \n",
    "\n",
    "from ROOT import TH1F \n",
    "from ROOT import TCanvas \n",
    "from ROOT import THStack \n",
    "from ROOT import TLegend \n",
    "from ROOT import TLatex \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7461a7c-77eb-4e0d-8066-7cb93c2a2789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_folder = \"/disco4/pheno_csv_files/Leptoquarks_Searches\"\n",
    "signals = [\"zp_tau_tau\",\"ta_ta\"]\n",
    "Masses = [\"1000\"]\n",
    "suffix_by_betard = {'woRHC': 'wo_RHC'}\n",
    "channels = ['hadronic_non-resonant','hadronic_sLQ','hadronic_dLQ','semileptonic_non-resonant','semileptonic_sLQ','semileptonic_dLQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e90d01ef-7482-4e5f-873b-fffcdf814ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/disco4/pheno_csv_files/Leptoquarks_Searches/zp_tau_tau_wo_RHC_m1000_g1_5/zp_tau_tau_wo_RHC_m1000_g1_5_hadronic_non-resonant.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msignal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix_by_betard[key]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_g1_5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m path_csv \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(csv_folder, folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m Datasets_signal[key][channel][M][signal] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_csv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/disco4/pheno_csv_files/Leptoquarks_Searches/zp_tau_tau_wo_RHC_m1000_g1_5/zp_tau_tau_wo_RHC_m1000_g1_5_hadronic_non-resonant.csv'"
     ]
    }
   ],
   "source": [
    "Datasets_signal = {} \n",
    "\n",
    "for key in suffix_by_betard:\n",
    "    Datasets_signal[key] = {}\n",
    "    for channel in channels:\n",
    "        Datasets_signal[key][channel] = {}\n",
    "        for M in Masses:\n",
    "            Datasets_signal[key][channel][M] = {}\n",
    "            for signal in signals:\n",
    "                Datasets_signal[key][channel][M][signal] = {}\n",
    "                folder = f'{signal}_{suffix_by_betard[key]}_m{M}_g1_5'\n",
    "                path_csv = os.path.join(csv_folder, folder, f'{folder}_{channel}.csv')\n",
    "                Datasets_signal[key][channel][M][signal] = pd.read_csv(path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "377433d0-6e55-4c90-8e22-f03f05d4f457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 220\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 09:34 LQ_LQ_1000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 10:50 LQ_LQ_1250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 01:56 LQ_LQ_1500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 02:33 LQ_LQ_1750\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 03:12 LQ_LQ_2000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 01:54 LQ_LQ_2250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 02:29 LQ_LQ_2500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 06:28 LQ_LQ_wo_RHC_1000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 07:35 LQ_LQ_wo_RHC_1250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 05:54 LQ_LQ_wo_RHC_1500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 07:02 LQ_LQ_wo_RHC_1750\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 08:06 LQ_LQ_wo_RHC_2000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 06:24 LQ_LQ_wo_RHC_2250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 07:31 LQ_LQ_wo_RHC_2500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 03:07 Tau_LQ_1000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 01:55 Tau_LQ_1250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 02:31 Tau_LQ_1500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 03:10 Tau_LQ_1750\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 03:48 Tau_LQ_2000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 04:27 Tau_LQ_2250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 05:06 Tau_LQ_2500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 08:59 Tau_LQ_wo_RHC_1000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 09:00 Tau_LQ_wo_RHC_1250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 10:37 Tau_LQ_wo_RHC_1500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 11:25 Tau_LQ_wo_RHC_1750\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 09:35 Tau_LQ_wo_RHC_2000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 11:00 Tau_LQ_wo_RHC_2250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 11:40 Tau_LQ_wo_RHC_2500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 03:43 Tau_Tau_1000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 04:12 Tau_Tau_1250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 04:42 Tau_Tau_1500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 03:46 Tau_Tau_1750\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 04:15 Tau_Tau_2000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 04:46 Tau_Tau_2250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 05:15 Tau_Tau_2500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 09:13 Tau_Tau_wo_RHC_1000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 09:29 Tau_Tau_wo_RHC_1250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 09:35 Tau_Tau_wo_RHC_1500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 10:02 Tau_Tau_wo_RHC_1750\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 10:21 Tau_Tau_wo_RHC_2000\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 10:34 Tau_Tau_wo_RHC_2250\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 10:47 Tau_Tau_wo_RHC_2500\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 17 19:05 Z_Tau_Tau\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 17 17:35 cutflows\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 17 19:05 cutflows_Z\n",
      "drwxr-xr-x. 2 root root 4096 May 10 18:14 cutflows_lq_zp\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 17 09:34 stop\n",
      "drwxr-xr-x. 2 root root 4096 May 10 18:05 ta_ta_m1000_g1_5\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 17 02:39 ttbar\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 10:38 w_jets\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 20:11 ww\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 17 03:24 wz\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 17 17:35 z_jets\n",
      "drwxr-xr-x. 2 root root 4096 May 10 18:14 zp_tau_tau_m1000_g1_5\n",
      "drwxr-xr-x. 2 1019 1019 4096 Mar 16 08:17 zz\n"
     ]
    }
   ],
   "source": [
    "!ls -l /disco4/pheno_csv_files/Leptoquarks_Searches/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cabf68-d95a-4a3e-a3e4-7ab44567d915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
