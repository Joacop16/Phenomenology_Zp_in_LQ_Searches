{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3971e8-4457-4363-99e0-9774f4b45695",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin PeÃ±uela Parra}$$\n",
    "$$\\textrm{University of Los Andes}$$\n",
    "$$\\textrm{High Energy Physics Group: Phenomenology of Particles}$$\n",
    "\n",
    "This code was written to be running in Docker. If you do not have a Docker inside hep-server2 please refer to: https://github.com/Phenomenology-group-uniandes/Tutoriales_Generales\n",
    "\n",
    "$\\textbf{Preliminaries}$ \n",
    "\n",
    "The libraries used here are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31de8954-690b-45db-97e6-152c4b150d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hint: Pulling without specifying how to reconcile divergent branches is\n",
      "hint: discouraged. You can squelch this message by running one of the following\n",
      "hint: commands sometime before your next pull:\n",
      "hint: \n",
      "hint:   git config pull.rebase false  # merge (the default strategy)\n",
      "hint:   git config pull.rebase true   # rebase\n",
      "hint:   git config pull.ff only       # fast-forward only\n",
      "hint: \n",
      "hint: You can replace \"git config\" with \"git config --global\" to set a default\n",
      "hint: preference for all repositories. You can also pass --rebase, --no-rebase,\n",
      "hint: or --ff-only on the command line to override the configured default per\n",
      "hint: invocation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "from ROOT import TCanvas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## IMPORTANT: Make sure that \"Uniandes_Framework\" is in .gitignore\n",
    "framework_path = \"Uniandes_Framework\"\n",
    "\n",
    "if os.path.exists(framework_path):\n",
    "    # Pull updates if the framework is already cloned\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"-C\", framework_path, \"pull\"])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise Exception(f\"Error occurred while pulling updates from the framework: {e}\")\n",
    "else:\n",
    "    # Clone the framework if it is not already cloned\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"clone\", \"git@github.com:Phenomenology-group-uniandes/Uniandes_Framework.git\"])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise Exception(f\"Error occurred while cloning the framework: {e}\")\n",
    "from Uniandes_Framework.delphes_reader.lhereader import LHE_Loader, readLHEF, get_event_by_child\n",
    "from Uniandes_Framework.delphes_reader.root_analysis import get_kinematics_row, make_histograms, overlap_histos, Quiet, generate_csv, sum_histos, histos_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a07109-c59f-4b02-85c4-3a045ac751a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder = 'Data_SDE_1'\n",
    "\n",
    "Betards = ['woRHC']\n",
    "zp_limits = ['zp_upper_limit', \n",
    "             'zp_lower_limit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cabe52b-ad6d-4ef9-b0e3-aaa1531b869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_options = {'ta_ta_virtual_contribution':  'generate p p > ta ta QED = 0 $$ zp', \n",
    "                      'ta_ta_real_contribution': 'generate p p > zp > ta ta QED = 0',\n",
    "                      'ta_ta_total_contribution': 'generate p p > ta ta QED = 0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e81bb9d-b349-41fb-bcb9-2c0feace9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Us = np.arange(1000,3500,500)\n",
    "g_Us = np.arange(0.5,1.5,0.5)\n",
    "g_Zps = np.arange(0.5,2,0.5)\n",
    "\n",
    "# M_Us = [1500]\n",
    "# g_Us = [1.0]\n",
    "# g_Zps = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ec226-dff3-4e2f-be01-eb8b541e2ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9688cdbb-1618-4fd9-b1b9-ecda2d69a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xs_from_html(signal, mu_gu_gzp_label, Betard, zp_limit):\n",
    "    html_path = os.path.join(os.getcwd(), Folder, Betard, zp_limit, signal,  mu_gu_gzp_label, 'crossx.html')\n",
    "    html_table = pd.read_html(html_path)\n",
    "    column_xs = html_table[0]['Cross section (pb)']\n",
    "    return float(column_xs[0].split(' ')[0])    \n",
    "\n",
    "csv_initial = pd.read_csv(os.path.join('Uniandes_Framework', 'SimulationsPaths.csv'))\n",
    "\n",
    "csv_final = pd.concat(\n",
    "                        [csv_initial]\n",
    "                        +\n",
    "                        [ pd.DataFrame.from_dict(\n",
    "                        {\n",
    "                            'name': f'{Betard}_{zp_limit}_{signal}_mu_{m}_gu_{gu}_gzp_{gzp}', \n",
    "                            'path': os.path.join(os.getcwd(), Folder, Betard, zp_limit, signal, f'mu_{m}_gu_{gu}_gzp_{gzp}'),  \n",
    "                            'xs(pb)': read_xs_from_html(signal, f'mu_{m}_gu_{gu}_gzp_{gzp}', Betard, zp_limit)\n",
    "                        }, \n",
    "                        orient = 'index').T for signal, m , gu, gzp, Betard, zp_limit in product(generation_options.keys(),M_Us,g_Us, g_Zps, Betards, zp_limits)]\n",
    "                     )\n",
    "\n",
    "# save the new csv\n",
    "csv_final.to_csv('SimulationsPaths.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5c6d15-1404-4e2f-b3ac-2f4eb9299cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lhe_file(signal):\n",
    "    global label, Betard, zp_limit, Folder\n",
    "    \n",
    "    signal_key = f'{Betard}_{zp_limit}_{signal}_{label}'\n",
    "    \n",
    "    lhe_loader = LHE_Loader(signal_key, os.path.join(os.getcwd(), 'SimulationsPaths.csv'))\n",
    "    lhe_path_files = lhe_loader.Forest\n",
    "        \n",
    "    results = list()\n",
    "    \n",
    "    for lhe_path_file in lhe_path_files:\n",
    "    \n",
    "        childs=readLHEF(lhe_path_file)\n",
    "\n",
    "        for child in childs:\n",
    "            event = get_event_by_child(child)\n",
    "            taus = event.getParticlesByIDs([-15,15])\n",
    "            if len(taus) != 2: continue\n",
    "            taus[0].SetName(\"#tau_{1}\")\n",
    "            taus[1].SetName(\"#tau_{2}\")\n",
    "            sum_taus = taus[0].TLV + taus[1].TLV\n",
    "            row = get_kinematics_row(taus)\n",
    "            row[\"m_ll(GeV)\"] = sum_taus.M()\n",
    "            row[\"sT(GeV)\"] = row[\"pT_{#tau_{1}}(GeV)\"] + row[\"pT_{#tau_{2}}(GeV)\"]\n",
    "            results.append(row)        \n",
    "    \n",
    "    generate_csv(results, os.path.join(Folder, Betard, zp_limit, signal, label, 'Kinematic_Information.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7a3c8e-c138-4108-b3bf-bcd389c1c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_options = {'ta_ta_virtual_contribution':  'generate p p > ta ta QED = 0 / zp', \n",
    "                      'ta_ta_real_contribution': 'generate p p > zp, zp > ta ta QED = 0',\n",
    "                      'ta_ta_total_contribution': 'generate p p > ta ta QED = 0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327dcd72-4533-4730-a9d0-b1274ebff9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woRHC_zp_upper_limit_ta_ta_real_contribution_mu_3000_gu_1.0_gzp_1.0 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_upper_limit/ta_ta_real_contribution/mu_3000_gu_1.0_gzp_1.0\n",
      "woRHC_zp_upper_limit_ta_ta_total_contribution_mu_3000_gu_1.0_gzp_1.0 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_upper_limit/ta_ta_total_contribution/mu_3000_gu_1.0_gzp_1.0woRHC_zp_upper_limit_ta_ta_virtual_contribution_mu_3000_gu_1.0_gzp_1.0 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_upper_limit/ta_ta_virtual_contribution/mu_3000_gu_1.0_gzp_1.0\n",
      "\n",
      "woRHC_zp_lower_limit_ta_ta_total_contribution_mu_3000_gu_1.0_gzp_1.0 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_lower_limit/ta_ta_total_contribution/mu_3000_gu_1.0_gzp_1.0woRHC_zp_lower_limit_ta_ta_real_contribution_mu_3000_gu_1.0_gzp_1.0 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_lower_limit/ta_ta_real_contribution/mu_3000_gu_1.0_gzp_1.0woRHC_zp_lower_limit_ta_ta_virtual_contribution_mu_3000_gu_1.0_gzp_1.0 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_lower_limit/ta_ta_virtual_contribution/mu_3000_gu_1.0_gzp_1.0\n",
      "\n",
      "\n",
      "woRHC_zp_upper_limit_ta_ta_real_contribution_mu_3000_gu_1.0_gzp_1.5 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_upper_limit/ta_ta_real_contribution/mu_3000_gu_1.0_gzp_1.5woRHC_zp_upper_limit_ta_ta_virtual_contribution_mu_3000_gu_1.0_gzp_1.5 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_upper_limit/ta_ta_virtual_contribution/mu_3000_gu_1.0_gzp_1.5woRHC_zp_upper_limit_ta_ta_total_contribution_mu_3000_gu_1.0_gzp_1.5 imported with 6 trees!\n",
      "/home/pheno/2023/Semanas_22_23_24/lq_zprime/01_signal_production/ta_ta_generation_testing/Data_SDE_1/woRHC/zp_upper_limit/ta_ta_total_contribution/mu_3000_gu_1.0_gzp_1.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mu , gu, gzp, Betard, zp_limit in product(M_Us,g_Us, g_Zps, Betards, zp_limits):\n",
    "    \n",
    "    label = f'mu_{mu}_gu_{gu}_gzp_{gzp}'\n",
    "    if not os.path.exists(os.path.join(Folder, Betard, zp_limit, 'ta_ta_virtual_contribution', label, 'Kinematic_Information.csv')):\n",
    "        with Pool(3) as p: p.map(read_lhe_file, generation_options.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f04333-61fc-4c3b-9b2c-b3b8e24aa923",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch acabo_Generate_CSVs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c877f2-e6f8-4756-8d51-814fd95f2dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
