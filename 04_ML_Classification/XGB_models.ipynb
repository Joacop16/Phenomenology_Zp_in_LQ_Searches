{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec752c0e-f46a-486f-ae0a-6b0dd8e6a642",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin Pe√±uela Parra, Cristian Fernando Rodriguez Cruz}$$\n",
    "$$\\textrm{University of Los Andes}$$\n",
    "$$\\textrm{High Energy Physics Group: Phenomenology of Particles}$$\n",
    "\n",
    "This code was written to be running in Docker. If you do not have a Docker inside hep-server2 please refer to: https://github.com/Phenomenology-group-uniandes/Tutoriales_Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb19389d-aacb-49db-920e-a856f2a81ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "def add_parent_lib_path(name=\"Leptoquarks_Searches_2023\"):\n",
    "    sys.path.append(sys.path[0].split(name)[0])\n",
    "    \n",
    "add_parent_lib_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3940aa-42b7-410c-aeed-22823bfe68cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import Uniandes_Framework\n",
    "from ROOT import *\n",
    "from Uniandes_Framework.ml_tools.xgb_classifier import XGB_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf05a73-5ac4-4731-b4f6-8121f3d173cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleos_cpu = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ceee13b-9313-4dcf-8682-2929876f6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminares: \n",
    "\n",
    "channels = [\"hadronic_dLQ\", \"hadronic_sLQ\", \"hadronic_non-resonant\", \"semileptonic_dLQ\", \"semileptonic_sLQ\", \"semileptonic_non-resonant\"]\n",
    "\n",
    "bkg_by_channel = {\"dLQ\": ['ttbar', 'z_jets'], \n",
    "                  \"sLQ\": ['ttbar', 'z_jets', 'stop'], \n",
    "                  \"non-resonant\": ['ttbar', 'z_jets', 'stop', 'diboson']}\n",
    "\n",
    "Masses = [\"1000\",'1250', '1500', '1750', '2000', '2250', '2500']\n",
    "signals = []\n",
    "signals += ['LQ_LQ_wo_RHC', 'Tau_LQ_wo_RHC', 'Tau_Tau_wo_RHC']\n",
    "signals += ['LQ_LQ', 'Tau_LQ', 'Tau_Tau']\n",
    "\n",
    "parameters={\n",
    "    \"n_estimators\":[\n",
    "        100,\n",
    "        125,\n",
    "        250,\n",
    "        500,\n",
    "        # 750,\n",
    "        # 1000\n",
    "    ],\n",
    "    \"max_depth\":[\n",
    "        3,\n",
    "        5,\n",
    "        7,\n",
    "        9\n",
    "    ],\n",
    "    \"learning_rate\":[\n",
    "        0.1\n",
    "    ]\n",
    "}\n",
    "\n",
    "bkg_names = ['ttbar', 'z_jets', 'stop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f86f510-57e4-42bf-b800-e701d172607d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_dLQ/M1000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_dLQ/M1250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_dLQ/M1500_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_dLQ/M1750_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_dLQ/M2000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_dLQ/M2250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_dLQ/M2500_XGB.joblib\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_sLQ/M1000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_sLQ/M1250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_sLQ/M1500_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_sLQ/M1750_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_sLQ/M2000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_sLQ/M2250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_sLQ/M2500_XGB.joblib\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_non-resonant/M1000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_non-resonant/M1250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_non-resonant/M1500_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_non-resonant/M1750_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_non-resonant/M2000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_non-resonant/M2250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/hadronic_non-resonant/M2500_XGB.joblib\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_dLQ/M1000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_dLQ/M1250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_dLQ/M1500_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_dLQ/M1750_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_dLQ/M2000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_dLQ/M2250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_dLQ/M2500_XGB.joblib\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_sLQ/M1000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_sLQ/M1250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_sLQ/M1500_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_sLQ/M1750_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_sLQ/M2000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_sLQ/M2250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_sLQ/M2500_XGB.joblib\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_non-resonant/M1000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_non-resonant/M1250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_non-resonant/M1500_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_non-resonant/M1750_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_non-resonant/M2000_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_non-resonant/M2250_XGB.joblib\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "======================================================================\n",
      "For the Gradient_Boosting model\n",
      "the Best Parameters are {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 125}\n",
      "The model was saved in: \n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/04_ML_Classification/XGB_models/semileptonic_non-resonant/M2500_XGB.joblib\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "try: os.mkdir('XGB_models')\n",
    "except: pass\n",
    "\n",
    "for channel in channels: \n",
    "    try: os.mkdir(f'XGB_models/{channel}')\n",
    "    except: pass\n",
    "    \n",
    "    initial_time = time.time()\n",
    "    \n",
    "    mass = '1750'\n",
    "    \n",
    "    signal_dict = {}\n",
    "    for signal in signals:\n",
    "        key=f\"{signal}_{mass}\"\n",
    "        signal_dict[key] = [os.path.join(os.sep,\"disco4\",\"pheno_csv_files\",\"Leptoquarks_Searches\",key,f\"{key}_{channel}.csv\")]\n",
    "        \n",
    "    bkg_dict = {}\n",
    "    for bkg in bkg_names: bkg_dict[bkg] = [os.path.join(os.sep,\"disco4\",\"pheno_csv_files\",\"Leptoquarks_Searches\",bkg,f\"{bkg}_{channel}.csv\")]\n",
    "    bkg_dict['diboson'] = [os.path.join(os.sep,\"disco4\",\"pheno_csv_files\",\"Leptoquarks_Searches\",bkg,f\"{bkg}_{channel}.csv\") for bkg in ['ww', 'wz', 'zz']]\n",
    "\n",
    "    bkgs_dict = {}\n",
    "    bkg_list = [bkg_by_channel[key] for key in bkg_by_channel if key in channel][0]\n",
    "    \n",
    "    \n",
    "    for bkg in bkg_list: bkgs_dict[bkg] = bkg_dict[bkg]\n",
    "        \n",
    "    model = XGB_Classifier(\n",
    "                            ncpu = nucleos_cpu,\n",
    "                            cv =10, \n",
    "                            parameters = parameters,\n",
    "                            signal_dictionary = signal_dict,\n",
    "                            bkg_dictionary = bkgs_dict,\n",
    "                            balance = True\n",
    "                            )\n",
    "    \n",
    "    best_features = model.get_most_important_features() \n",
    "    \n",
    "    if not(\"sT(GeV)\" in best_features):\n",
    "            best_features += [\"sT(GeV)\"]\n",
    "    \n",
    "    ######################################################\n",
    "    #Writing .txt:\n",
    "    with open(os.path.join(os.getcwd(), 'XGB_models', channel, f'Most_Important_Features.txt'), \"w\") as f:\n",
    "        for feature in best_features: f.write(feature +\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    best_params = {'learning_rate': model.learning_rate, 'max_depth': model.max_depth, 'n_estimators': model.n_estimators}\n",
    "    \n",
    "    output_model_channel = [f'For the {model.model_name} model',\n",
    "                            f'The Best Parameters are {best_params}',\n",
    "                            'The most important variables are:',\n",
    "                             str(best_features)]\n",
    "    \n",
    "    with open(os.path.join(os.getcwd(), 'XGB_models', channel, f'Output_console.txt'), \"w\") as f: \n",
    "        for line in output_model_channel: f.write(line +\"\\n\")\n",
    "    f.close()    \n",
    "    ######################################################\n",
    "    \n",
    "    for mass in Masses:\n",
    "        \n",
    "        signal_dict = {}\n",
    "        for signal in signals:\n",
    "            key=f\"{signal}_{mass}\"\n",
    "            signal_dict[key] = [os.path.join(os.sep,\"disco4\",\"pheno_csv_files\",\"Leptoquarks_Searches\",key,f\"{key}_{channel}.csv\")]      \n",
    "            \n",
    "        model = XGB_Classifier(\n",
    "                                ncpu = nucleos_cpu,\n",
    "                                cv =5, \n",
    "                                parameters = parameters,\n",
    "                                signal_dictionary = signal_dict,\n",
    "                                bkg_dictionary = bkgs_dict,\n",
    "                                balance = True\n",
    "                                )    \n",
    "\n",
    "        model.filter_by_features(best_features, n_pca = 10)\n",
    "        metrics = model.get_metrics()\n",
    "        model.save_model(path_to_save= os.path.join(os.getcwd(), 'XGB_models',channel), file_name= f'M{mass}_XGB.joblib')\n",
    "        \n",
    "        ######################################################\n",
    "        #Writing .txt files:\n",
    "        best_params = {'learning_rate': model.learning_rate, 'max_depth': model.max_depth, 'n_estimators': model.n_estimators}\n",
    "        model_path = os.path.join(os.getcwd(), 'XGB_models', channel, f'M{mass}_XGB.joblib')\n",
    "        output_model_mass = ['=='*80,\n",
    "                              f'Mass: {mass}, channel: {channel}',\n",
    "                              f'For the {model.model_name} model',\n",
    "                              f'The Best Parameters are {best_params}',\n",
    "                              f'The train accuracy is {metrics[1]} and the test test accuracy is {metrics[0]}',\n",
    "                              'The most important variables are:',\n",
    "                              str(model.importances_df),\n",
    "                              f'trainLab size: {len(model.trainLab)}, trainPred size: {len(model.trainPred)}',\n",
    "                              f'signal_dict = {signal_dict}',\n",
    "                              f'bkgs_dict = {bkgs_dict}',\n",
    "                              f'The model was saved in: {model_path}']        \n",
    "        \n",
    "        with open(os.path.join(os.getcwd(), 'XGB_models', channel, f'Output_console.txt'), \"a\") as f: \n",
    "            for line in output_model_mass: f.write(line +\"\\n\")   \n",
    "        f.close()\n",
    "        ######################################################\n",
    "\n",
    "    ######################################################\n",
    "    #Writing .txt files:\n",
    "    final_time = time.time()\n",
    "    with open(os.path.join(os.getcwd(), 'XGB_models', channel, f'Output_console.txt'), \"a\") as f: f.write(f'The channel {channel} takes {(final_time - initial_time)/3600} hours.')\n",
    "    f.close()\n",
    "    ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0457459-05c1-4729-a7db-e4c75b0a35bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!touch XBG_models_acabo.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
