{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6716b3b-5f41-4a4c-af1e-69ff2502c918",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin Pe√±uela Parra}$$\n",
    "$$\\textrm{University of Los Andes}$$\n",
    "$$\\textrm{High Energy Physics Group: Phenomenology of Particles}$$\n",
    "\n",
    "This code was written to be running in Docker. If you do not have a Docker inside hep-server2 please refer to: https://github.com/Phenomenology-group-uniandes/Tutoriales_Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753a5d42-946a-43d2-8a9f-80e1a80f2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "def add_parent_lib_path(name=\"lq_zprime\"):\n",
    "    sys.path.append(sys.path[0].split(name)[0])\n",
    "    \n",
    "add_parent_lib_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89acd650-fd08-4367-9136-953b8a965ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_Leptoquarks_searches = os.path.dirname(os.path.dirname(os.path.realpath('XBG_Discriminator_Histograms.ipynb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203aa837-feb7-4963-93e9-7ecc2f31d928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    }
   ],
   "source": [
    "from Uniandes_Framework.ml_tools import tools\n",
    "from Uniandes_Framework.delphes_reader import root_analysis\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ROOT import TCanvas #Permite poner los histogramas\n",
    "from ROOT import THStack #Permite graficar varios histogramas al mismo tiempo\n",
    "from ROOT import TLegend #Permite poner legends cuando se sobrelapan histogramas\n",
    "from ROOT import TLatex #Permite poner avisos en Latex en las graficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa195a7-4406-49b0-9a30-b3cedd1b54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [\"hadronic_dLQ\", \"hadronic_sLQ\", \"hadronic_non-resonant\", \"semileptonic_dLQ\", \"semileptonic_sLQ\", \"semileptonic_non-resonant\"]\n",
    "signals = ['LQ_LQ', 'Tau_LQ', 'Tau_Tau'] + ['LQ_LQ_wo_RHC', 'Tau_LQ_wo_RHC', 'Tau_Tau_wo_RHC']\n",
    "Masses = [\n",
    "    \"1000\" \n",
    "]\n",
    "\n",
    "bkgs = ['ttbar', 'z_jets', 'w_jets', 'stop','ww', 'wz', 'zz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab2fa3a-9ca0-481e-be69-8e7af5fa72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zp_signals = ['zp_tau_tau_m1000_g1_5', 'ta_ta_m1000_g1_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8821e8b-b016-4eaa-a46c-e37fcc94d4cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:53] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[14:24:54] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[14:24:55] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[14:24:56] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[14:24:57] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[14:24:58] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try: os.mkdir('Histograms')\n",
    "except: pass\n",
    "\n",
    "def escape_braces(strings):\n",
    "    escaped_strings = []\n",
    "    for s in strings:\n",
    "        #escaped_s = s.replace('#tau', 'tau_jet').replace('b', 'b_jet').replace('#Delta R', '#Delta{R}').replace('#Delta ', '#Delta').replace('#Delta#eta', '#Delta{#eta}').replace('#Delta#phi', '#Delta{#phi}')\n",
    "        escaped_s = s.replace('#Delta R', '#Delta{R}').replace('#Delta ', '#Delta').replace('#DeltapT', '#Delta{pT}').replace('#Delta#eta', '#Delta{#eta}').replace('#Delta#phi', '#Delta{#phi}')\n",
    "        escaped_strings.append(\"{}\".format(escaped_s))\n",
    "    return escaped_strings\n",
    "\n",
    "# def escape_braces(strings):\n",
    "#     escaped_strings = []\n",
    "#     for s in strings:\n",
    "#         escaped_s = s.replace('{', '{{').replace('}', '}}')\n",
    "#         escaped_strings.append(\"{}\".format(escaped_s))\n",
    "#     return escaped_strings\n",
    "\n",
    "for channel in channels:\n",
    "    try: os.mkdir(f'Histograms/{channel}')\n",
    "    except: pass    \n",
    "    \n",
    "    most_important_features = []\n",
    "    with open(os.path.join(os.getcwd(), 'XGB_models', channel, f'Most_Important_Features.txt'), \"r\") as f:\n",
    "        for line in f: most_important_features.append(line.strip())\n",
    "    f.close()\n",
    "        \n",
    "    for Mass in Masses:\n",
    "        try: os.mkdir(f'Histograms/{channel}/M{Mass}')\n",
    "        except: pass\n",
    "        \n",
    "        bkg_dict = {}\n",
    "        signal_dict = {}\n",
    "        \n",
    "        signal_dict['zp_tau_tau_m1000_g1_5'] = os.path.join(os.sep,\"disco4\",\"pheno_csv_files\",\"Leptoquarks_Searches\",'zp_tau_tau_m1000_g1_5',f\"zp_tau_tau_m1000_g1_5_{channel}.csv\")\n",
    "        signal_dict['ta_ta_m1000_g1_5'] = os.path.join(os.sep,\"disco4\",\"pheno_csv_files\",\"Leptoquarks_Searches\",'ta_ta_m1000_g1_5',f\"ta_ta_m1000_g1_5_{channel}.csv\")\n",
    "        \n",
    "        path_model_mass =  os.path.join(os.getcwd(), 'XGB_models', channel, f'M{Mass}_XGB.joblib')\n",
    "        bkg_and_signal_dict = bkg_dict | signal_dict\n",
    "        path_folder_mass = os.path.join(os.getcwd(), 'Histograms', channel, f'M{Mass}')\n",
    "        \n",
    "        with root_analysis.Quiet(): tools.hist_discriminator(path_model= path_model_mass, csv_dict = bkg_and_signal_dict, path_to_save= path_folder_mass, best_features= escape_braces(most_important_features), old_features = most_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88856f20-0dc6-485a-bde3-a6d21332881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "for channel in channels:\n",
    "    \n",
    "    root_file_path = os.path.join(\"Histograms\",channel,\"M1000\", \"Histograms_M1000_XGB.root\")\n",
    "    histos = root_analysis.Read_ROOT_File(root_file_path, ['zp_tau_tau_m1000_g1_5', 'ta_ta_m1000_g1_5'])\n",
    "    \n",
    "    Histos_Dictionary = {'zp_tau_tau': {'XGB-Output': histos['zp_tau_tau_m1000_g1_5']},'ta_ta': {'XGB-Output': histos['ta_ta_m1000_g1_5']}}\n",
    "    \n",
    "    Histos, Canva, Legend = root_analysis.overlap_histos(kinematic_variable= 'XGB-Output', \n",
    "                                                         Dict_Histos= Histos_Dictionary)  \n",
    "    Canva.SetLogy()\n",
    "    Legend.SetHeader(\"M1000 y g1.5\",\"C\")\n",
    "    \n",
    "    with root_analysis.Quiet(): Canva.SaveAs(os.path.join(\"Histograms\",channel,\"M1000\", \"Overlap.png\"))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab87618-07e3-457c-b293-989e17335641",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch termino_XGB_Discriminator_Histograms.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb67b75-44b6-4f8a-bb34-08eef4b5ee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
